{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "\n",
    "# 打开Chrome（需配置webdriver）\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "def get_mgtv_danmu(month_num, day_num, num1, num2):\n",
    "    step = 1\n",
    "    df_all = pd.DataFrame()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # 第一集URL\n",
    "            danmu_url = 'https://bullet-ws.hitv.com/bullet/2020/{}/{}/{}/{}/{}.json'.format(month_num, day_num, num1, num2, step)\n",
    "\n",
    "            # 打印进度\n",
    "            print('正在获取第{}页的信息'.format(step))\n",
    "            step += 1\n",
    "            # 获取弹幕\n",
    "            browser.get(danmu_url)\n",
    "\n",
    "            # 休眠3秒\n",
    "            time.sleep(3)\n",
    "\n",
    "            # 提取数据\n",
    "            pattern1 = re.compile(r'<html><head></head><body><pre style=\"word-wrap: break-word; white-space: pre-wrap;\">')\n",
    "            pattern2 = re.compile(r'</pre></body></html>')\n",
    "\n",
    "            data1 = re.sub(pattern1, '', browser.page_source)\n",
    "            data2 = re.sub(pattern2, '', data1)\n",
    "\n",
    "            # 解析数据\n",
    "            js_data = json.loads(data2)\n",
    "\n",
    "            # 获取数据\n",
    "            all_data = js_data['data']['items']\n",
    "\n",
    "            # id\n",
    "            danmu_id = [i.get('id') for i in all_data]\n",
    "            # uname\n",
    "            uname = [i.get('uname') for i in all_data]\n",
    "            # 内容\n",
    "            content = [i.get('content') for i in all_data]\n",
    "            # 时间\n",
    "            danmu_time = [i.get('time') for i in all_data]\n",
    "            # 点赞\n",
    "            up_count = [i.get('v2_up_count') for i in all_data]\n",
    "            # 分钟\n",
    "            danmu_minites = step-1\n",
    "\n",
    "            # 保存数据\n",
    "            df_one = pd.DataFrame({\n",
    "                'danmu_id': danmu_id,\n",
    "                'uname': uname,\n",
    "                'content': content,\n",
    "                'danmu_time': danmu_time,\n",
    "                'up_count': up_count,\n",
    "                'danmu_minites': danmu_minites\n",
    "            })\n",
    "\n",
    "            # 循环追加\n",
    "            df_all = df_all.append(df_one, ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('没有此页面, 爬虫结束')\n",
    "            break\n",
    "\n",
    "    return df_all\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # \n",
    "    df_1 = get_mgtv_danmu(month_num='06', day_num='21', num1=104556, num2=8337559) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
